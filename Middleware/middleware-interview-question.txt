A) Pure Q&A for Drilling – Middleware Architecture & Custom Middleware (30+ Questions)
Basics (Warm-up Qs)

    What is middleware in Express.js?
    How does Express.js middleware differ from route handlers?
    What are the different types of middleware in Express.js?
    What happens if you forget to call next() inside middleware?
    How does error-handling middleware differ from normal middleware?
    How do you add multiple middleware functions to a single route?
    What is the role of app.use() vs app.get() in middleware registration?

Intermediate Qs (Applied Concepts)

    How do you implement a custom logger middleware (without using morgan)?
    How do you handle authentication using middleware (JWT/session)?
    Explain how middleware order affects request processing in Express.
    How do you restrict middleware execution only for specific routes?
    How do you implement role-based access control (RBAC) using middleware?
    Explain how to use router-level middleware in Express.
    How would you pass data from one middleware to another?
    Can middleware be async? What issues arise if you don’t handle async properly?

Advanced Qs (Scalability + Patterns)

    How do you implement rate limiting middleware from scratch?
    How do you implement request throttling differently from rate limiting?
    What are best practices for error-handling middleware?
    How would you implement CORS handling as a middleware?
    How would you implement a request ID propagation middleware for microservices?
    How do you write a middleware that logs request timings (profiling)?
    How do you handle body parsing without using express.json()?
    Can middleware short-circuit request processing? Give an example.
    How do you implement feature flags using middleware?
    What’s the difference between middleware in Express vs Redux?  
    Why should performance-critical middleware be mounted selectively and not globally?

System Design & Architecture Level Qs

    How would you design middleware flow in an API Gateway for microservices?
    What should be the order of middleware execution in an e-commerce API (logging, security, auth, rate-limiting, etc.)?
    How do you ensure middleware works efficiently in a high-concurrency environment?
    In distributed systems, where should you implement middleware: API Gateway, service level, or both?
    How would you design middleware for multi-tenant applications (different middleware per tenant)?
    How do you implement request retries and fallback inside middleware?
    How do you integrate monitoring tools (e.g., Prometheus, ELK) using middleware?
    How to design a plug-and-play middleware architecture for a SaaS product?

B) Scenario-Based Mock Interview
🎯 Scenario 1: API Gateway Middleware Design

Question:
    You’re designing an API Gateway for a large e-commerce platform. The Gateway must handle:
        i. Authentication (JWT-based)
        ii. Role-based authorization (admin, seller, buyer)
        iii. Rate limiting (100 req/min per IP)
        iv. Request logging with correlation ID
        v. Error handling (unified format)

👉 How would you structure middleware? Explain ordering, implementation details, and trade-offs.

Expected Answer (Summary):
    Order of middleware:

        1. requestIdMiddleware (assigns UUID per request → helps with tracing)
        2. loggerMiddleware (logs method, URL, requestId)
        3. rateLimiterMiddleware (protects API from abuse)
        4. authMiddleware (verifies JWT, attaches user info)
        5. roleCheckMiddleware (checks permissions)
        6. Route handler
        7. errorHandlerMiddleware (catches unhandled errors, standard JSON response)

    Implementation considerations:
        1. Use Redis for distributed rate limiting.
        2. JWT validation must be stateless (no DB lookup per request).
        3. Logging middleware should push logs asynchronously (Kafka/ELK).
        4. Error handler should follow a standardized format across services.

🎯 Scenario 2: Custom Middleware in Microservices

Question: Your microservices need consistent request tracing across services for debugging. How would you implement a middleware for request correlation IDs?

Expected Answer:

    1. At Gateway → generate X-Request-ID header (UUID).
    2. Middleware attaches it to req.id.
    3. Downstream services propagate the same ID in logs and responses.
    4. Benefits → allows tracing a single request across 10+ microservices.

🎯 Scenario 3: Rate Limiting & Performance

Question: Suppose you need to implement rate limiting middleware. At 10K concurrent requests/sec, how would you ensure performance?

Expected Answer:

    1. Naïve solution: In-memory Map (fails with horizontal scaling).
    2. Scalable solution: Redis with sliding window / token bucket algorithm.
    3. Middleware implementation: Async Redis calls → if exceeded limit, return 429.
    4. Optimization: Use Lua scripts in Redis to avoid race conditions.

🎯 Scenario 4: Multi-Tenant Middleware

Question: You’re building a SaaS app. Each tenant requires different middleware (e.g., custom logging, feature flags). How do you architect this?

Expected Answer:

    1. Maintain tenant metadata in DB (enabled middlewares).
    2. Global middleware inspects req.tenantId.
    3. Dynamically attach middlewares using app.use() or per-route router.use().
    4. Example: Tenant A has caching middleware, Tenant B does not.

🎯 Scenario 5: Error Handling

Question: How would you design a global error-handling middleware so all APIs return a consistent error structure like { success: false, message: "", traceId: "" }?

Expected Answer:

    1. Final middleware:

function errorHandler(err, req, res, next) {
    res.status(err.status || 500).json({
        success: false,
        message: err.message || "Internal Server Error",
        traceId: req.id
    });
}
app.use(errorHandler);


    2. Benefits → uniform error handling across all services.

Rate limiter
const rateLimiters = new Map(); // { ip: { count, lastReset } }

function rateLimiter(req, res, next) {
    const ip = req.ip;
    const now = Date.now();

    if (!rateLimiters.has(ip)) {
        rateLimiters.set(ip, { count: 1, lastReset: now });
        return next();
    }

    let limiter = rateLimiters.get(ip);
    if (now - limiter.lastReset > 15 * 60 * 1000) {
        limiter = { count: 1, lastReset: now }; // reset window
        rateLimiters.set(ip, limiter);
        return next();
    }

    if (limiter.count >= 100) {
        return res.status(429).json({ message: "Too many requests" });
    }

    limiter.count++;
    next();
}


Error Handling in Express & Async Patterns
1. Centralized Error Handling Middleware

📌 Question : Implement a global error handler in Express so you don’t repeat try/catch everywhere.

✅ Expected Answer

// errorHandler.js
function errorHandler(err, req, res, next) {
    console.error(`[Error] ${err.message}`);

    res.status(err.status || 500).json({
        success: false,
        message: err.message || "Internal Server Error"
    });
}

module.exports = errorHandler;


👉 Usage:

const express = require("express");
const errorHandler = require("./errorHandler");
const app = express();

app.get("/error", (req, res) => {
    throw new Error("Something went wrong!");
});

app.use(errorHandler); // must be last

2. Async Error Management Without Try/Catch Everywhere

📌 Problem
If you write this:
app.get("/users", async (req, res) => {
   const users = await User.find(); // if it throws → unhandled promise rejection
   res.json(users);
});

You’d need try/catch everywhere → messy.

✅ Solution → asyncHandler wrapper
const asyncHandler = (fn) => (req, res, next) => {
    Promise.resolve(fn(req, res, next)).catch(next);
};

// usage
app.get("/users", asyncHandler(async (req, res) => {
    const users = await User.find();
    res.json(users);
}));
Now all errors go to your global errorHandler.


3. Error Classes for Clean Code

📌 Question: Design a system where you can throw custom errors with status codes.

✅ Solution

class AppError extends Error {
    constructor(message, status) {
        super(message);
        this.status = status;
    }
}

// usage in route
app.get("/notfound", (req, res, next) => {
    next(new AppError("Resource Not Found", 404));
});
Your errorHandler will catch and return status 404 instead of always 500.

4. Error Handling in Middleware
    o. Auth middleware → throw 401 if token invalid.
    o. Validation middleware → throw 400 with validation errors.
    o.DB middleware → convert DB errors into meaningful messages.

5. Advanced Async Patterns (Interview Level)
    o. Parallel error handling: Use Promise.allSettled() when running multiple async ops and you don’t want one failure to crash all.
    o. Background jobs: Decouple errors in async tasks (e.g., RabbitMQ/Redis queues).
    o. Graceful shutdown: Catch unhandledRejection / uncaughtException at process level.

process.on("unhandledRejection", (reason, promise) => {
    console.error("Unhandled Rejection:", reason);
});

💡 Typical Interview Questions

    1. How do you handle async errors in Express without repeating try/catch?
    2. Difference between error middleware vs normal middleware?
    3. How would you propagate DB validation errors (like Mongoose ValidationError) into user-friendly responses?
    4. How do you handle unhandled promise rejections in Node?
    5. If your async middleware throws an error before next(), how does Express catch it?

===================================================
🛡 Security Best Practices in Middleware
1. Helmet – Secure HTTP Headers

    What it does: Adds secure HTTP headers to prevent common attacks.
    Covers against:
        Cross-Site Scripting (XSS)
        Clickjacking
        MIME-type sniffing

Middleware Example:

    const helmet = require("helmet");
    app.use(helmet());

2. Rate Limiting – Prevent Brute Force / DoS

    o. What it does: Limits number of requests per IP to prevent brute force attacks or denial-of-service (DoS).
    o. Middleware Example:

        const rateLimit = require("express-rate-limit");
        const limiter = rateLimit({
            windowMs: 15 * 60 * 1000, // 15 minutes
            max: 100, // 100 requests per window
            message: "Too many requests, try again later."
        });
        app.use(limiter);

3. CORS – Restrict Origins

    o. What it does: Controls which domains can access your API.
    o. Problem it solves: Prevents unauthorized cross-origin requests.
    o. Middleware Example:
        
        const cors = require("cors");
        app.use(cors({
            origin: ["https://my-frontend.com"], // whitelist
            methods: ["GET", "POST", "PUT"],
            credentials: true
        }));

4. Body Size Limiting – Prevent Payload Attacks

    o. What it does: Stops attackers from sending huge request bodies to exhaust memory.
    o. Middleware Example:
        app.use(express.json({ limit: "10kb" }));

5. Data Sanitization – Prevent Injection

    o. What it does: Cleans user input to prevent NoSQL injection and XSS attacks.
    o. Middleware Example:
        const mongoSanitize = require("express-mongo-sanitize");
        const xss = require("xss-clean");
        app.use(mongoSanitize()); // Prevent NoSQL injection
        app.use(xss());           // Prevent XSS attacks

6. Hide Technology Stack

    o. What it does: Hides Express from headers (X-Powered-By) to reduce attack surface.
    o. Middleware Example:
        app.disable("x-powered-by");

7. Session & Cookie Security

    Always set httpOnly, secure, and sameSite attributes in cookies.
    app.use(session({
        secret: process.env.SESSION_SECRET,
        cookie: {
            httpOnly: true,
            secure: true,
            sameSite: "strict"
        }
    }));

🎯 Interview-Focused Talking Points (for 8 YOE)

If interviewer asks “How do you secure middleware in Express?”, answer like this:

“We follow layered middleware security. First, we use helmet to set secure HTTP headers, then apply rate-limiting on sensitive endpoints like login to prevent brute force. We restrict origins with CORS, and limit payload size to mitigate DoS attacks. For data integrity, we sanitize input using express-mongo-sanitize and xss-clean. Finally, we disable headers like X-Powered-By and ensure cookies are httpOnly, secure, and sameSite. This holistic middleware security approach helps protect against XSS, CSRF, NoSQL injection, and other common vulnerabilities.”


=================================================
🔹 API Design Patterns at Middleware Level

1. Request Pre-Processing Pattern

    Purpose: Validate and normalize incoming requests before business logic.
    Examples:
        JSON schema validation (Ajv, Joi).
        Auto-trimming/normalizing strings.

2. Cross-Cutting Concerns Pattern

    Purpose: Apply common functionality across all APIs at middleware.
    Examples:
        Logging (request/response).
        Authentication/Authorization.
        Error handling.

    Code Example (Logger):
        const morgan = require("morgan");
        app.use(morgan("combined"));

3. Security Enforcement Pattern

    Purpose: Apply security middleware consistently to avoid duplicated logic.
    Examples:
        o. helmet() for headers.
        o. Rate limiting.
        o. CORS setup.

5. Error Handling Pattern

    Purpose: Centralized error-handling middleware to avoid scattered try/catch.
    Code Example:

        app.use((err, req, res, next) => {
            console.error(err.stack);
            res.status(err.status || 500).json({
                error: err.message || "Something went wrong!"
            });
        });

6. Rate Limiting / Throttling Pattern

    Purpose: Control abuse of sensitive endpoints.
    Pattern: Place middleware selectively (e.g., only on /login, not all routes).


7. Middleware Chaining Pattern

    Purpose: Split complex logic into smaller, reusable middleware functions chained together.


🎯 How to Present in Interview (8 YOE)

If asked “What API design patterns do you apply at the middleware level?”:
“I structure middleware around cross-cutting concerns. Requests first pass through security layers (helmet, CORS, rate limiting), then validation middlewares to enforce schema. I use routing & composition patterns by modularizing routes with their own middleware stacks. Errors are captured by a centralized error handler to maintain consistency. For scalability, I apply API versioning middleware and wrap responses in a standard response format. Finally, I add observability middleware for monitoring latency and usage. This ensures APIs remain secure, maintainable, and predictable across teams.”


=================================================
🔹 Performance Optimization & Caching Strategies in Middleware

Middleware sits between the request and the route handler, making it an ideal place to implement performance enhancements before requests hit business logic.

1. Response Caching Middleware
    o. Idea: Cache frequently requested responses in memory or distributed cache (Redis).
    o. When to Use: GET APIs with static or slow-changing data (e.g., product catalog, configs).
    Code Example (Redis Cache):
            
        const redis = require("redis");
        const client = redis.createClient();

        const cacheMiddleware = (req, res, next) => {
            const key = req.originalUrl;
            client.get(key, (err, data) => {
                if (data) {
                    return res.json(JSON.parse(data)); // serve from cache
                }
                res.sendResponse = res.json;
                res.json = (body) => {
                    client.setex(key, 60, JSON.stringify(body)); // cache for 60s
                    res.sendResponse(body);
                };
                next();
            });
        };

    app.get("/products", cacheMiddleware, (req, res) => {
        // heavy DB call
        res.json({ products: ["laptop", "phone"] });
    });

2. Conditional GET & ETag Middleware

    o. Idea: Use HTTP caching headers so the browser/CDN can reuse responses.
    o. ETag Example:

    const etag = require("etag");

    app.use((req, res, next) => {
        res.setHeader("ETag", etag(JSON.stringify(res.body || {})));
        next();
    });

    o. Browser sends If-None-Match → server responds with 304 Not Modified (no payload).

3. Compression Middleware

    o. Idea: Reduce payload size with gzip/brotli at middleware level.
    o. Code Example:

        const compression = require("compression");
        app.use(compression()); // auto-compress responses

4. Request De-Duplication / Idempotency

    o. Idea: Avoid executing heavy logic twice for the same client request.
    o. Pattern: Use request IDs + cache at middleware.
    o. Example Use Case: Payment APIs.

5. Rate Limiting + Throttling

    o. Idea: Protect backend from performance degradation under high load.
    o. Code Example:
        const rateLimit = require("express-rate-limit");
        app.use(rateLimit({ windowMs: 60 * 1000, max: 100 }));

6. Database Query Caching

    o. Idea: Cache DB query results at middleware instead of hitting DB each time.
    o. Pattern:
        o. Check Redis/Memory at middleware.
        o. If miss → hit DB → store in cache → return.

7. Lazy Loading & Streaming

    o. Idea: Optimize big payloads by streaming response instead of loading all in memory.
    o. Example: Sending CSV/Logs via res.write() in middleware before controller.

8. Asynchronous & Non-Blocking Middleware

    o. Idea: Ensure middlewares do not block the event loop.
    o. Pattern: Avoid sync file I/O, prefer async.
    o. Bad Example (blocking):
        app.use((req, res, next) => {
            const data = fs.readFileSync("config.json"); // BLOCKS event loop
            next();
        });

    o. Good Example (non-blocking):
        app.use(async (req, res, next) => {
            const data = await fs.promises.readFile("config.json", "utf8");
            next();
        });

9. CDN + Edge Caching Integration

    o. Middleware can add cache-control headers to leverage CDNs:

        app.use((req, res, next) => {
            res.setHeader("Cache-Control", "public, max-age=3600"); // cache for 1 hr
            next();
        });

10. Metrics and Bottleneck Detection

    o. Middleware should measure response times to detect performance issues.
    o. Code Example:
        app.use((req, res, next) => {
            const start = Date.now();
            res.on("finish", () => {
                const duration = Date.now() - start;
                console.log(`${req.method} ${req.originalUrl} - ${duration}ms`);
            });
            next();
        });

🎯 How to Present in Interview (8 YOE)

If asked “How do you optimize API performance at middleware level?”:

“I introduce caching at multiple levels — response caching middleware with Redis for frequently used GET APIs, and ETag/Last-Modified headers for client-side/browser caching. For payload size optimization, I use compression middleware 
and sometimes streaming responses for large files. I enforce rate limiting and request de-duplication to reduce load on downstream systems. Middleware also adds Cache-Control headers to leverage CDN caching. On top of that, I ensure middleware 
is non-blocking and instrument it with metrics to detect slow routes. This layered caching + optimization strategy ensures both high throughput and low latency.”



